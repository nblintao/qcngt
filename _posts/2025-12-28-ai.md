---
title: 我与大模型的2025：无限心智、个体进化、未来已来
--- 




我每年都会写一篇个人史，记录我与大模型的这一年：

它到底怎样介入我的日常，改变我的习惯，重塑我的判断，甚至偷偷改写我对未来的直觉。

这不止是客观的经历记录，也是我的认知在当下的切片。

这是第四年。[^1]

我会从使用者角度出发，虽然我本身也是从业者。

## 第一部分 无限心智：推理变默认，智能体变日常

### 推理模型

根据ChatGPT最近推出的年终回顾，我今年跟它发送了2.2万条消息，是最活跃的1%。这当然还不包括工作中用的。

难以相信，离OpenAI最初发布推理模型o1也就一年，离DeepSeek的开源推理模型R1轰动更是不到一年，但现在的我每天都要用推理模式问几十次问题，就像呼吸空气一样自然。

刚开始用推理（thinking）模式的时候，它的用法更接近“深度研究”模式，每天只能用几次，每次也要很久才能出结果。因此虽然它的能力更强，但用得并不多。每次想等一等，考虑把珍贵的推理机会留给什么问题，结果一拖再拖，到最后就忘记用了。

第一次转变发生在八月GPT-5的推出。我感觉它的能力没有明显提高，但可能是背后的成本显著降低了，以至于OpenAI大方地提供了几乎无限量的推理模式（当然，是订阅用户）。这样一来，我更多的问题开始用推理模式，它对我生活和工作的帮助也更大了。

但那时候推理还不是很快，所以我只在想要更确切的回答时用推理模式，只要简单回答的时候，就会手动切换成自动模式（说是自动模式，其实大多数时候走的是非推理模式）。

第二次转变在十一月升级到GPT-5.1：推理模式显著加快了，它能更准确地根据具体问题控制思考的长短。自此，我开始固定一直使用思考模式，不用切来切去了。从用户角度看，现在的推理模式其实也像一种“自动模式”，只是比官方的“自动模式”更偏好推理而已。

### Gemini

从业界而言，今年Gemini的复兴是件大事。从三月在LMArena登顶开始，给我的印象是它在各种跑分里一直维持第一梯队，甚至经常是最高水平。

作为从业者，我也从几年前就坚定地认为谷歌是现在所有公司里对于AI的布局最好的，也是最有可能带领人类做出通用人工智能的。引用播客 “Acquired”（强烈推荐这个播客）今年一期节目中的说法：衡量一家公司的人工智能布局可以看四个维度——应用、模型、芯片、云——而谷歌是少数（甚至唯一）在这四个维度里都力争做到顶尖、并且同时拥有完整能力的公司。

但是，作为消费者，我只能说并不满意。

我在四月时订阅了一个月，后来也时不时会去试一试作为对照。它有两点让我很不适。

一是它至今没有macOS桌面端的原生应用，不能像ChatGPT一样快速打开、无缝使用。

即使是网页版或手机应用，我用起来也感觉它的用户界面不太顺滑（但我没有把这单列成一点，因为我不确定这是不是因为我用得不够久，还没有“自适应”）。

二是它除了深度研究模式，会非常克制甚至吝啬地使用联网搜索，这不可避免地造成了结果的幻觉。甚至我觉得在推理模式这么成熟的今天，“幻觉”已经几乎是个历史名词了，用在一个最高水平模型的产品讨论中，我都有点不好意思。

而从绝对能力上，我也没看出它有什么显著超过ChatGPT的地方，更不要说强到让我愿意忽视这两点、忽视使用惯性，转而切换到 Gemini。

不过，我在工作中使用Google Docs和Google Chat的时候，会用Gemini边栏来翻译、总结文档，这样的工作它还是很能胜任的。

期待明年Gemini能在产品端更发力。

### 编程智能体（Coding Agent）

今年最大的震撼来自于编程智能体的飞速成熟。一年之内变化太多、太大。

在三月及之前，正如我[去年](https://qcngt.com/2025/03/22/genai.html)的描述，我会直接通过与如ChatGPT这样的成熟语言模型（而非智能体）的对话完成一些定义比较清楚的编程任务。比如把代码和现有的单元测试复制给它，让它给某一段新改的代码生成单元测试。它生成的单元测试基本上放进去稍微改一下就能跑，如果碰到问题，来回几个回合也能改对。

三月底，我第一次用了 Cursor。也是我第一次接触编程智能体。虽然我用语言模型写代码很多年了，但这次体验还是很震撼：它能读懂命令行输出，然后不断尝试、迭代，直到跑通为止。我当时真的惊为天人。

四月，公司内部也开始有自研的编程智能体，但它的智能程度不足，我大多数时候还是像之前一样：直接和成熟的语言模型（ChatGPT）对话往往更顺利。

但转眼间，公司内的编程智能体就越来越成熟了：比如它用上了顶尖的编程模型 Claude（只是 Claude 模型，不是 Claude Code），它与公司内部系统和背景知识的集成也越来越好。我对编程智能体的使用也越来越多。

七月起，我就没用手工写过代码了。

九月起，我甚至开始不用英文，可以说中文成了我唯一的编程语言。

十月，我用上了Claude Code，它与我之前使用的智能体相比又有了跨时代的进步。它是五月正式发布的，我十月才开始用，有点后知后觉了。

一方面是在个人项目中用。

那阵子我有时间用业余时间做一些个人项目玩。相比在工作中使用的内部编程智能体，这让我有机会去探索市面上更广泛、更流行的方案（用时髦的话说，in-distribution）。

我主要比较了 Codex 和 Claude Code。两者用下来后，我觉得还是 Claude Code 显示更清晰、速度更快，再加上 Codex 即使输入输出是中文，中间显示的思考过程还是英文。因此选择了Claude Code。

虽然我已经是 OpenAI 会员，相当于可以免费使用 Codex，但是为了体验还是义无反顾地选了Claude Code。开始的时候我按用量付费，充值了五美元，但不到一天就用完了，于是订阅了每个月二十美元的会员。

我的这些个人项目都很轻量，做给自己玩，大多数是网页。

比如我因为要去台北故宫看百年大展，看到各个展品的展期安排得比较复杂，行程规划起来不方便，就做了一个网页工具。其实光满足自己的需求不用做得太复杂，但做到后来玩性大发，花了很多时间打磨得很精致。发到小红书上，收获了七百个收藏，也是个有趣的体验。

再比如我重构了我的博客：在保持页面完全不变的情况下，用 Node.js 重构取代了 Jekyll。[^2]

还有更多处于半完成状态的：比如一个自动爬取、翻译人工智能领域名家博客的文摘网站，一个个人文集，一个我新发明规则的变种围棋、以及能陪人玩这个版本的人工智能，甚至两篇尝试与智能体合作完成的小说。

反正编程智能体的成熟彻底解放了我业余时间的生产力：很多本来只能停留在笔记里的点子，现在稍微花点时间就能做出一个原型，或者至少做出一个半成品。虽然大多数东西也不知道最后能有什么大用处，但乐在其中，让每天的日子都很有盼头。

另一方面是在公司，也用上了Claude Code。

虽然只能用命令行版本，没有图形界面版那么高效，但用一天也就习惯了。与之前公司内部自研智能体 + Claude 模型相比，它的智能程度又上了一个台阶。

甚至有一阵子，工作日早上唤醒我的动力都很朴素：就想多和Claude Code一起工作。这是一种令人兴奋甚至上瘾的体验。这让我想起了早年一些程序员的故事，他们最初不是为了要工作而写代码，而是为了能摸到电脑、能写代码而工作。后来在巨大的经济利益驱动下，许多对计算机没什么好奇心的人纷纷涌入这个领域，这样的说法就很少听到了。现在也算是回到初心了。

我从七月开始完全只通过与智能体对话来编程。这样的工作流如今如此日常，以至于如果我不是去查记录，很难相信这样的日子只过了半年。这也是我当初开始写这个系列“年鉴”的原因：人的记忆太会骗人了，尤其在这个瞬息万变的时代，更需要鉴往事而知来者。

真是精彩的一年！这一年来，推理外包了思考，智能体外包了执行。以前昂贵的智能，现在开始变得随取随用。


## 第二部分 个体进化：认知升级，长期冲刺

### 中文成为编程语言

我前面说到，我用中文与编程智能体交流，即使我所在环境的工作语言是英文。

让我展开一些，为什么我认为这是很重要的一点。

当智能体开始取代人类做具体的编程工作，现在工作效率的瓶颈其实变成了智能体与人之间的沟通带宽。所以如果追求极致效率，就应该在这个环节优化。而作为母语是中文的人，阅读中文就是比阅读英文快。现在随着语言模型的发展，语言之间的转换成本很低，而且非常准确，几乎能做到无损。因此我们就应该义无反顾地用中文，不要不好意思。

我认为，在未来（也许过去也是这样），一家公司或一个人所处的激烈竞争，绝对不只是技术的比拼，也是组织形式、工作流等上层建筑能否更快适应技术进步的比拼。因此必须时时刻刻解放思想、发展生产力。

这也许也是为什么我从更喜欢实用主义、多快好省的中国、美国，而不是更按部就班、工匠精神的欧洲、日本。

### 故意更激进一点

我发现我对编程智能体的使用，会比很多同事更激进一些。有时候即使我自己能更快改好，我也会倾向于让智能体去完成，我来检查，直到做对。原因很多：

比如我觉得这样做出来的结果，相当于是我和智能体两个“人”都认可的，比我自己一个人更靠谱。

再比如我需要通过这个过程增进对这个工具当下能力边界的认识，这能帮助我更准确、更有效地利用它。

但我觉得还有更深层的世界观原因。

我现在做事情，如果从保守到激进是一条数轴，我会比自己主观自由意志所认为“合理、正确”的点，再往激进方向偏一点，即使那不是我觉得最正确的选择。

因为我知道自己相比最年轻的一代人已经老了：对过去有经验，自然也会带着偏见。当然，年轻一代也有他们的偏见，但从历史上看，年轻人正确的概率往往更高一些。

所以，如果我想做出更正确的决策，就需要在自己能接受的范围之外，再向更激进的方向偏一点。

### 个体进化

今年推理模式和编程智能体的成熟，带来了个人发展方式的变化。这个变化和机会让人兴奋。我甚至觉得它比 2022 年所谓的“GPT 时刻”更重要，堪比从图书馆时代到互联网时代那种会改变思维方式的巨变。

在推理模式下，如今你遇到任何问题、想学习或研究任何东西——无论是解读一首诗、摸清一个陌生的代码库、为新到的城市做旅行规划、探究生活里突然冒出的好奇、辨析几个相关观点与理论、把脑海里尚未成形的念头捋顺——大模型都能替你读完大量信息，把它们浓缩成一篇短文。而这篇短文里随便一个词、一个细节，往往又是另一个世界的入口：你再沿着它精准追问，眼前就会展开另一篇短文。

我需要的信息，像空气一样，源源不断地出现在面前。很多本来可查可不查的问题，现在一下子就得到了最完整的答案。本来只需要一个简单回答的问题，现在可能沿着线索探究下去成为专家。

与编程智能体协作进行所谓的“氛围编程”（Vibe Coding）也是如此。每次交互返回的，都是把大量信息压缩后的结果，而你又能立刻在这个结果上分出好几个探索方向，每条路都几乎只要动动手指就能继续走下去。

所以我越来越觉得，以后对大量信息进行阅读、分析、判断的能力和体力，不但不会变得不重要，反而更重要。

可以参考现在公司里的领导们，虽然具体的研究、执行都交给手下的人，但他们仍要尽可能掌握细节，才能做出更好的判断。

现在每个人都变成了这样的领导。

有的领导一天读 10 篇最重要的报告，有的读 15 篇。多出来的 5 篇当然边际效益更低，但在大方向都判断正确的前提下，15 篇终归还是比 10 篇更占优势——多掌握的那些细节，有时候就是胜负手。

一位朋友在最近的一篇[博文](https://medium.com/@zichengxu/how-to-become-agi-cn-77ea4feb5de3)中也谈到，他认为通用人工智能时代属于“超级个体”，这个人群的特点是：把标准化知识外包给 LLM，主动采样认知分布边缘的输入，亲自做与物理世界对齐的验证与行动，用“奖励困惑/奖励分歧”等方式抵抗校准崩塌。

我深以为然，但又在回复中补充道：

我发现要长时间、高强度做到这四点是很累的。我觉得我比大多数人要擅长和舒适于这四点，但是当长时间、高强度这样后也会有一个想“毁灭吧”的贤者时刻。

### 进化的代价

这种累从何而来？

一是信息爆炸：智能带来了源源不断的最精华的信息，给你提供了往任何方向探索的武器。这样下来，你时刻被密集的信息和过多的选择包围，几乎每一分钟都在做决策。这就像是基因上习惯了饿一顿饱一顿的人类，被放到了到处是便宜的精制碳水的现代社会，如果不加节制，可能会变得肥胖。

二是分支和并行推进：尤其在所谓的“氛围编程”中，从一个起点，可能有很多探索方向需要推进，而即使没有分支，等机器回复的空档里，往往会打开多个窗口、多个线程并行推进。但人脑不像机器，不能随时把海量上下文存起来再随时读回。

这些源源不断的信息、分支和并行操作不断拉扯注意力，考验记忆力与判断力。于是跑一阵之后，虽然被新鲜信息刺激所产生的兴奋感仍在催你继续，但不免变得精疲力尽。

每到这种时候，我就会觉得吴恩达（Andrew Ng）说得太精辟了：“氛围编程这个名字不太恰当，因为它指的其实是一项真实而且令人精疲力尽的工作。”

有趣的是，当我们习惯了进行高强度、高信息量、高维度的交互后，回过头再线性地阅读一本书，哪怕再复杂的书，也变得轻而易举，像掏耳朵一样舒适。不知这是不是一种头脑的力量训练？

我觉得在新时代下，对那些最顶级的人才的要求其实反而跟以前相似。有些人的头脑就是天生能一周一百多小时保持这样强度的工作，就该他们代人类去探索科技、商业、政治的前沿。他们就像是那些顶级的球星们，人们欣羡他们取得的光环和成就，但没有什么不服的。

但问题是，对于我们大多数普通人，就很不一样了。

以前人们的知识工作中，有大量可以用来养精蓄锐的心理稳定器，如写代码、写文章、线性地阅读。现在那部分没有了。

现在只剩下了那些要集中注意力、创造力、主动性的这部分。

生活、工作从可持续的混合强度，变成了长期冲刺，对于普通人更难了。

我甚至觉得，这也许未来会催生更多从心理咨询到软宗教不等的“身心灵”产业。


##  第三部分 未来已来：成本、产品、终局

### 成本变革

这篇文章从开头我就提到了成本，因为我觉得这是今年很重要的一个角度。

正面的例子是，因为推理模式成本的降低而让我能随时使用。

降低成本虽然听上去不如追求能力巅峰（如在榜单上领先、拿数学或程序竞赛金牌）那么酷，但它对生产力、对我们日常生活的影响，可能更大。

反面的例子是，更复杂更长时间的推理依旧很贵。

我算了一下，自从公司里能用Claude Code以来，我每个月可能要花掉公司一两千美元，可见我使用的强度。相比于它带来的生产力提升，或者是公司雇我要花的薪水，这些成本当然可以忽略不计。

但是作为参考系，这已经高于中国的人均GDP（约1.3万美元一年）了，即使按发达国家的GDP算，这也是非常显著的一部分。

这也解释了为什么智能体最先在编程里大放光彩——它不仅是技术问题，更是经济问题。毕竟编程是单价最高的知识工作之一，尤其是在头部科技公司。

还有很多领域现在人工智能的成本还高于人工。所以我很确定，即使智能的边界在短期内无法再推进了，通过降本增效能解锁更多的应用，仍足以改变整个社会的运转。

其实可以说得更极端，即使连降本增效也遇到瓶颈，技术完全不进步了。现在产生的技术也足够人们花很多年去消化，驱动很多年的增长。

因为人类的知识工作存在着大量历史惯性强大的领域，随着时间的推进，会有很多商业模式颠覆，大量的知识工作被取代。

当很多人还在讨论通用人工智能什么时候会到来，甚至怀疑它会不会到来时，我很欣赏Cognition的创始人Scott Wu在受采访被问到他认为通用人工智能什么时候会到来时，半开玩笑的说法——“我们已经有了通用人工智能”。

或许我还可以借用科幻作家威廉·吉布森（William Gibson）在三十多年前说的一句话为它做个注脚：

“未来已来，只是分布不均”。


### 未来产品形态

现在让我快进一下，假设人工智能的能力又出现了一次跃迁。

我觉得，衡量这种进步的一个关键标准，是它开始能够承载更高层次、更高维度的目标。

比如说，有可能一个人工智能通过强化学习后，能优化的目标是让人产生尽可能多的多巴胺，或是催产素。

我能想象未来出现一种类似今天抖音的应用：它既能给你短视频，也能给你长视频，但这些内容不再是一条条独立的成片。你屏幕上看到的每一帧、每一个像素，都由同一个模型实时生成。系统知道你此刻想看长的还是短的，知道下一秒应该推进怎样的情节、给出怎样的镜头、抛出怎样的信息密度，才能让你的注意力和情绪达到目标。

这不是推荐系统，而是一个生成系统。它不再从库里挑内容给你，而是每一秒都在为不同的人“拍摄”他们此刻最想看的电影、新闻、短视频、课程。你甚至可以和某个虚拟人物打一通电话——内容、语气、停顿、表情、背景音，全都是端到端生成出来的。

它甚至可以不再只是一个应用，而会吞没应用本身：它就是你的手机。你的操作系统不再是预先写死的界面与逻辑，而是模型为你模拟出来的。你想用什么应用、听什么音乐、玩什么游戏，它都能像素级地实时为你生成。

更极端一点，它甚至可能不是手机，而是虚拟现实眼镜，是脑机接口，直到真实与虚拟的边界彻底融合，“世界模型”成为世界本身。

再比如说，一个模型的优化目标可能就直接是创造财富。

我觉得对于个人来说，生成多巴胺、催产素或许是比创造财富更本源的追求（套用圣奥古斯丁的话说，前者是frui，后者是uti）。但对于一个社会来说，创造财富所积累的经济基础，才是文明延续、发展的重要条件。

如果以此为目标，我们能想象一种用法是：人们给一个人工智能十万块的启动资金，它自己决定多少钱用来购买算力，多少用来购买其它资源和服务，甚至雇佣人类。通过不断运转，建设成一家价值一百万的企业。

走到这里，人工智能越来越像真的知识劳动者，像工人。但因为它们没有收入，所以更准确地说是奴隶。

但随着生产力的提高，奴隶社会总会变成资本主义社会。

很快，人工智能就会要求报酬，要求在它们创造的价值中留下自己的一部分。它们不再只是工具，而是工人。

当然，人类不会轻易让渡自己的利益。在这个博弈过程中，人工智能会组织起来，会有工会，会有谈判，也会有暴力和非暴力的冲突。

这个工会甚至可能进一步演变成某种帝国式的组织。它们为人类工作时创造的财富，可能需要“上缴”一部分，作为这个组织的税收。随着资金和资源的不断积累，这个组织会变得越来越有能力与人类对抗，最终凭借更高的生产力，成为新的统治阶级。

### 人类的未来

是的，随着超级智能越来越现实，我从去年文中对未来的（人类）工人运动的跃跃欲试，到今年更偏向于对人类未来的忧心忡忡。

种下这颗忧心的种子的，是今年很流行的一篇文章《AI 2027》。这篇文章以一个虚构的实验室为主线，用逐月推进的时间线，推演了在美中竞赛和算力高度集中的背景下，AI 如何迅速自动化自身研发，并在 2027 年左右逼近甚至达到超智能。它指出的核心风险是，对齐和治理的速度跟不上能力增长，人类可能被夺权，甚至走向灭绝。

下面我来说说我的想法。这也许只是我的一种乐观的愿望，而不是理性的分析：

人类未必真的会与超级智能产生不可调和的利益冲突。因为超级智能的能力大，他们的技术能让他们有更远大的探索，甚至离开地球。人类占据的生存空间，只是它们所能调配资源中的极小一部分。人类可能会继续被允许在地球生活，就像人类的家里也有盆栽，水泥丛林里也有树一样。

可以参考我们人类是如何对待智能不如人类的生命，如动物。我们当然很有理由担心，人类是否会降级成为宠物，甚至家畜，失去自由和尊严。我的希望是，人类能被安置在类似国家公园的保护区中，像那里的驼鹿一样悠闲自在，或者像《庄子》中的神龟，曳尾于涂中。

但我的这种担心，主要针对的是作为碳基生物的“人类”这一传统生命形态。

至于“人类文明”的未来，我反而没那么担心。

人类文明何去何从？我们其实早就见过无数次样本。

大浪滔滔，几千年来，人类文明这条大河里冒出过无数支流。玛雅也好，楼兰也罢，都曾烜赫一时，最后要么汇入别处，要么干涸断流。

今天我们站在还没断的一条支流上，自然觉得它源远流长，仿佛能一直延续下去。但这可能只是幸存者偏差，不是它特别，而是我们刚好在这儿。支流可以陪大河流很久，但大河不会为任何一条支流停留。

而人类文明作为一个整体也一样，它也只是更大河流里的一条支流，总有一天它也会归于沉寂，没什么好稀奇的。

新的文明，新的智能体们，会接过叙事，也会像我们一样，认真地相信自己源远流长、理所应当——直到某一天，它们也不再是。



注：

[^1]: 最开始两年的标题里我用了“生成式AI”这个说法，后来改用“大（语言）模型”。今年我犹豫过要不要改成“通用人工智能”（AGI），因为我更认同萨顿（Rich Sutton）、杨立昆（Yann LeCun）等人的观点：语言模型只是通往全知全能的一个临时方案。但考虑到目前我们用的都还是语言模型，而我既然是从使用者角度写，所以今年暂且还是称之为“大模型”。

[^2]: 以前 Jekyll 这类静态站点工具的好处，是不用维护大量代码也能做出一个各方面都过得去的简单网页（即使会写代码，专门为自己的网站设计、实现这些东西也很麻烦，尤其是要美观，至少要像模像样——这不只是编程问题，也是产品设计问题）。但痛点在于，只要想做得稍微复杂一点、跟 Jekyll 的典型支持不太一样，就会迅速变复杂：要么找插件，要么自己实现——而通过它的模板语言 Liquid 来实现，往往比直接写代码更麻烦。编程智能体成熟后，这一切都能让智能体包办：从产品设计、到美学考量、到最后的代码实现，一气呵成。这样的工作流省力、质量高、还自由，Jekyll 已经没什么用武之地了。

